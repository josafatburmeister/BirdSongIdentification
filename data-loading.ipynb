{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Setup file path manager"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation import filepaths\n",
    "\n",
    "path_manager = filepaths.PathManager(\"./data\")\n"
   ]
  },
  {
   "source": [
    "## Download audio files and metadata from xeno-canto"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple species found for noise sample\n",
      "Skipping class noise sample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download label file for Alauda arvensis...: 100%|██████████| 4/4 [00:10<00:00,  2.63s/it]/it]\n",
      "Download label file for Anthus trivialis...: 100%|██████████| 3/3 [00:17<00:00,  5.84s/it]]\n",
      "Download label file for Buteo buteo...: 100%|██████████| 2/2 [00:09<00:00,  4.94s/it]\n",
      "Download label file for Linaria cannabina...: 100%|██████████| 3/3 [00:05<00:00,  1.67s/it]\n",
      "Download label file for Carduelis carduelis...: 100%|██████████| 4/4 [00:07<00:00,  1.88s/it]\n",
      "Download label file for Aegithalos caudatus...: 100%|██████████| 3/3 [00:45<00:00, 15.33s/it]\n",
      "Download label file for Certhia brachydactyla...: 100%|██████████| 2/2 [00:05<00:00,  2.60s/it]\n",
      "Download label file for Chloris chloris...: 100%|██████████| 4/4 [00:07<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple species found for Cicadatra atra\n",
      "Skipping class Cicadatra atra\n",
      "Multiple species found for Cicada orni\n",
      "Skipping class Cicada orni\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download label file for Cettia cetti...: 100%|██████████| 3/3 [00:22<00:00,  7.39s/it]\n",
      "Download label file for Chloris chloris...: 100%|██████████| 4/4 [00:14<00:00,  3.64s/it]\n",
      "Download label file for Columba palumbus...: 100%|██████████| 2/2 [00:17<00:00,  8.70s/it]]]\n",
      "Download label file for Corvus corone...: 100%|██████████| 3/3 [00:12<00:00,  4.19s/it]\n",
      "Download label file for Emberiza cirlus...: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]t]\n",
      "Download label file for Galerida cristata...: 100%|██████████| 1/1 [00:00<00:00, 17.40it/s]t]\n",
      "Download label file for Garrulus glandarius...: 100%|██████████| 3/3 [00:09<00:00,  3.29s/it]\n",
      "Download label file for Jynx torquilla...: 100%|██████████| 1/1 [00:02<00:00,  2.43s/it]]\n",
      "Download label file for Lophophanes cristatus...: 100%|██████████| 2/2 [00:12<00:00,  6.22s/it]\n",
      "Download label file for Cisticola juncidis...: 100%|██████████| 2/2 [01:56<00:00, 58.45s/it]\n",
      "Download label file for Dendrocopos major...: 100%|██████████| 4/4 [01:39<00:00, 24.90s/it]\n",
      "Download label file for Erithacus rubecula...: 100%|██████████| 8/8 [01:23<00:00, 10.49s/it]\n",
      "Download label file for Fringilla coelebs...: 100%|██████████| 10/10 [01:02<00:00,  6.20s/it]\n",
      "Download label file for Hirundo rustica...: 100%|██████████| 3/3 [00:25<00:00,  8.45s/it]\n",
      "Download label file for lullula arborea...: 100%|██████████| 2/2 [00:09<00:00,  4.86s/it]2s/it]\n",
      "Download label file for Luscinia megarhynchos...: 100%|██████████| 4/4 [00:07<00:00,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple species found for Lyristes plebejus\n",
      "Skipping class Lyristes plebejus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download label file for Motacilla cinerea...: 100%|██████████| 2/2 [00:14<00:00,  7.26s/it]\n",
      "Download label file for Muscicapa striata...: 100%|██████████| 2/2 [00:09<00:00,  4.92s/it]\n",
      "Download label file for Oriolus oriolus...: 100%|██████████| 2/2 [00:05<00:00,  2.51s/it]\n",
      "Download label file for Loxia curvirostra...: 100%|██████████| 7/7 [01:58<00:00, 16.97s/it]t]\n",
      "Download label file for Luscinia megarhynchos...: 100%|██████████| 4/4 [01:36<00:00, 24.04s/it]\n",
      "Download label file for Periparus ater...: 100%|██████████| 5/5 [01:09<00:00, 13.84s/it]\n",
      "Download label file for Cyanistes caeruleus...: 100%|██████████| 7/7 [00:56<00:00,  8.06s/it]\n",
      "Download label file for Parus major...: 100%|██████████| 13/13 [00:37<00:00,  2.86s/it]\n",
      "Download label file for Passer domesticus...: 100%|██████████| 4/4 [00:07<00:00,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple species found for Pelophylax kl. grafi\n",
      "Skipping class Pelophylax kl. grafi\n",
      "Multiple species found for Pholidoptera femorata\n",
      "Skipping class Pholidoptera femorata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download label file for Pica pica...: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]0,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple species found for Platycleis affinis\n",
      "Skipping class Platycleis affinis\n",
      "Multiple species found for Platycleis sabulosa\n",
      "Skipping class Platycleis sabulosa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download label file for Pica pica...: 100%|██████████| 2/2 [00:12<00:00,  6.49s/it]\n",
      "Download label file for Prunella modularis...: 100%|██████████| 4/4 [00:07<00:00,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple species found for Pteronemobius heydenii\n",
      "Skipping class Pteronemobius heydenii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download label file for Prunella modularis...: 100%|██████████| 4/4 [00:13<00:00,  3.41s/it]\n",
      "Download label file for Pyrrhula pyrrhula...: 100%|██████████| 3/3 [00:15<00:00,  5.10s/it]t]\n",
      "Download label file for Regulus ignicapilla...: 100%|██████████| 2/2 [00:07<00:00,  3.76s/it]\n",
      "Download label file for Sitta europaea...: 100%|██████████| 3/3 [00:05<00:00,  1.75s/it]]\n",
      "Download label file for Streptopelia turtur...: 100%|██████████| 1/1 [00:02<00:00,  2.56s/it]t]\n",
      "Download label file for Streptopelia decaocto...: 100%|██████████| 2/2 [00:12<00:00,  6.29s/it]\n",
      "Download label file for Sylvia cantillans...: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]]\n",
      "Download label file for Sylvia melanocephala...: 100%|██████████| 3/3 [00:04<00:00,  1.65s/it]\n",
      "Download label file for Sylvia undata...: 100%|██████████| 1/1 [00:00<00:00, 19.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple species found for Tettigettula pygmea\n",
      "Skipping class Tettigettula pygmea\n",
      "Multiple species found for Tibicina tomentosa\n",
      "Skipping class Tibicina tomentosa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download label file for Passer domesticus...: 100%|██████████| 4/4 [02:39<00:00, 39.80s/it]4s/it]\n",
      "Download label file for Phylloscopus collybita...: 100%|██████████| 9/9 [02:24<00:00, 16.05s/it]\n",
      "Download label file for Poecile palustris...: 100%|██████████| 3/3 [01:49<00:00, 36.66s/it]\n",
      "Download label file for Serinus serinus...: 100%|██████████| 3/3 [01:16<00:00, 25.34s/it]\n",
      "Download label file for Sturnus vulgaris...: 100%|██████████| 3/3 [00:53<00:00, 17.86s/it]\n",
      "Download label file for Sylvia atricapilla...: 100%|██████████| 7/7 [00:45<00:00,  6.52s/it]\n",
      "Download test set:  99%|█████████▊| 922/935 [07:53<00:13,  1.03s/it].21it/s]:00,  2.48s/it]6s/it]"
     ]
    }
   ],
   "source": [
    "from data_preparation import downloader\n",
    "\n",
    "downloader = downloader.XenoCantoDownloader(path_manager)\n",
    "\n",
    "downloader.create_datasets(\"nips4b_species_list.csv\", min_quality=\"A\", sound_types=[\"song\", \"call\"],    maximum_number_of_background_species=1)"
   ]
  },
  {
   "source": [
    "## Create spectrograms from audio files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download training set: 100%|██████████| 4666/4666 [1:04:54<00:00,  1.20it/s]\n",
      "Download validation set: 100%|██████████| 1590/1590 [25:57<00:00,  1.02it/s]\n",
      "Download test set: 100%|██████████| 935/935 [12:46<00:00,  1.22it/s]\n",
      "Download label file for Troglodytes troglodytes...: 100%|██████████| 7/7 [1:06:01<00:00, 565.92s/it]\n",
      "Download label file for Turdus merula...: 100%|██████████| 11/11 [1:05:43<00:00, 358.50s/it]\n",
      "Download label file for Turdus philomelos...: 100%|██████████| 8/8 [1:05:13<00:00, 489.24s/it]\n",
      "Create spectrograms for training set: 100%|██████████| 3074/3074 [3:33:24<00:00,  4.68s/it]   "
     ]
    },
    {
     "ename": "NameError",
     "evalue": "No matching labels found for file with id 100542",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-724a912758bc>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m     1000, path_manager)\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m \u001B[0mspectrogram_creator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcreate_spectrograms_for_datasets\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdatasets\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"train\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"val\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"test\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\BirdSongIdentification\\data_preparation\\spectrograms.py\u001B[0m in \u001B[0;36mcreate_spectrograms_for_datasets\u001B[1;34m(self, datasets)\u001B[0m\n\u001B[0;32m    193\u001B[0m             self.create_spectrograms_from_dir(\n\u001B[0;32m    194\u001B[0m                 audio_dir, spectrogram_dir, desc)\n\u001B[1;32m--> 195\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcreate_spectrogram_labels\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabel_file\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mspectrogram_dir\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    196\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    197\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mcreate_spectrogram_labels\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabel_file\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mspectrogram_dir\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\BirdSongIdentification\\data_preparation\\spectrograms.py\u001B[0m in \u001B[0;36mcreate_spectrogram_labels\u001B[1;34m(self, label_file, spectrogram_dir)\u001B[0m\n\u001B[0;32m    210\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    211\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabel\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 212\u001B[1;33m                     raise NameError(\n\u001B[0m\u001B[0;32m    213\u001B[0m                         \"No matching labels found for file with id {}\".format(file_id))\n\u001B[0;32m    214\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: No matching labels found for file with id 100542"
     ]
    }
   ],
   "source": [
    "from data_preparation import spectrograms\n",
    "\n",
    "spectrogram_creator = spectrograms.SpectrogramCreator(\n",
    "    1000, path_manager)\n",
    "\n",
    "spectrogram_creator.create_spectrograms_for_datasets(datasets=[\"train\", \"val\", \"test\"])"
   ]
  },
  {
   "source": [
    "## Create datasets and dataloaders"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_set = dataset.XenoCantoSpectrograms(\n",
    "    path_manager, chunk_length=1000, split=\"train\")\n",
    "train_loader = DataLoader(\n",
    "    train_set, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "val_set = dataset.XenoCantoSpectrograms(\n",
    "    path_manager, chunk_length=1000, split=\"val\")\n",
    "val_loader = DataLoader(\n",
    "    val_set, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "test_set = dataset.XenoCantoSpectrograms(\n",
    "    path_manager, chunk_length=1000, split=\"test\")\n",
    "test_loader = DataLoader(\n",
    "    test_set, batch_size=2, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data\\\\train\\\\spectrograms_1000\\\\433015-168.png'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-5-98963bb9bdc5>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    100\u001B[0m \u001B[0mexp_lr_scheduler\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlr_scheduler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mStepLR\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmy_optimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstep_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m7\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgamma\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    101\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 102\u001B[1;33m my_model = train_model(resnet_model, my_criterion, my_optimizer, exp_lr_scheduler,\n\u001B[0m\u001B[0;32m    103\u001B[0m                        num_epochs=25)\n",
      "\u001B[1;32m<ipython-input-5-98963bb9bdc5>\u001B[0m in \u001B[0;36mtrain_model\u001B[1;34m(model, criterion, optimizer, scheduler, num_epochs)\u001B[0m\n\u001B[0;32m     25\u001B[0m         \u001B[0mrunning_corrects\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 27\u001B[1;33m         \u001B[1;32mfor\u001B[0m \u001B[0mimages_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels_train\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtrain_loader\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     28\u001B[0m             \u001B[1;31m# TODO: Labels muessen hier noch richtig als Tensor übergeben werden\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m             \u001B[0mlabels_train\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimages_train\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlong\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\user\\pycharmprojects\\birdsongidentification\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    515\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_sampler_iter\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    516\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 517\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    518\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    519\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[1;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\user\\pycharmprojects\\birdsongidentification\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    555\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    556\u001B[0m         \u001B[0mindex\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# may raise StopIteration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 557\u001B[1;33m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# may raise StopIteration\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    558\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    559\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\user\\pycharmprojects\\birdsongidentification\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     42\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 44\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     45\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\user\\pycharmprojects\\birdsongidentification\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     42\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 44\u001B[1;33m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     45\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m             \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\PycharmProjects\\BirdSongIdentification\\training\\dataset.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     65\u001B[0m             self.data_dir, self.labels[\"file_name\"].iloc[idx])\n\u001B[0;32m     66\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 67\u001B[1;33m         \u001B[0mimage\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mImage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimg_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconvert\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'RGB'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     68\u001B[0m         \u001B[0mlabel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlabels\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0miloc\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"label\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m         \u001B[0mclass_id\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mclass_to_idx\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mlabel\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\user\\pycharmprojects\\birdsongidentification\\venv\\lib\\site-packages\\PIL\\Image.py\u001B[0m in \u001B[0;36mopen\u001B[1;34m(fp, mode, formats)\u001B[0m\n\u001B[0;32m   2910\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2911\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mfilename\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2912\u001B[1;33m         \u001B[0mfp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbuiltins\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"rb\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2913\u001B[0m         \u001B[0mexclusive_fp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2914\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './data\\\\train\\\\spectrograms_1000\\\\433015-168.png'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "from torchvision import models\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('----------')\n",
    "\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for images_train, labels_train in train_loader:\n",
    "            # TODO: Labels muessen hier noch richtig als Tensor übergeben werden\n",
    "            labels_train = torch.zeros(images_train.shape[0], dtype=torch.long)\n",
    "            images_train = images_train.to(device)\n",
    "            labels_train = labels_train.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(True):\n",
    "                images_out = model(images_train)\n",
    "                _, preds = torch.max(images_out, 1)\n",
    "                loss = criterion(images_out, labels_train)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images_train.size(0)\n",
    "            running_corrects += torch.sum(preds == labels_train.data)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / len(train_set)\n",
    "            epoch_acc = running_corrects.double() / len(train_set)\n",
    "\n",
    "           # print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "           #     'train', epoch_loss, epoch_acc))\n",
    "\n",
    "            # Evaluate Model\n",
    "            model.eval()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for images_val, labels_val in val_loader:\n",
    "                # TODO: Labels muessen hier noch richtig als Tensor übergeben werden\n",
    "                labels_val = torch.zeros(images_val.shape[0], dtype=torch.long)\n",
    "                images_val = images_val.to(device)\n",
    "                labels_val = labels_val.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(images_val)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels_val)\n",
    "\n",
    "                running_loss += loss.item() * images_val.size(0)\n",
    "                running_corrects += torch.sum(preds == labels_val.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(val_set)\n",
    "            epoch_acc = running_corrects.double() / len(val_set)\n",
    "\n",
    "           # print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "            #    'val', epoch_loss, epoch_acc))\n",
    "\n",
    "            if epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "resnet_model = models.resnet18()\n",
    "resnet_model.to(device)\n",
    "\n",
    "my_criterion = nn.CrossEntropyLoss()\n",
    "my_optimizer = optim.SGD(resnet_model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(my_optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "my_model = train_model(resnet_model, my_criterion, my_optimizer, exp_lr_scheduler,\n",
    "                       num_epochs=25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}